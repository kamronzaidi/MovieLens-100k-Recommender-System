{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\kirby\\anaconda3\\lib\\site-packages (3.2)\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "!pip install wget\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from heapq import nlargest\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import wget\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "wget.download(\"https://github.com/MIE451-2022/course-datasets/blob/main/ml-100k.zip\")\n",
    "!unzip ml-100k.zip\n",
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOVIELENS_DIR = \"ml-100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls {MOVIELENS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(folder_path, file_name):\n",
    "    fields = ['userID', 'itemID', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(os.path.join(folder_path, file_name), sep='\\t', names=fields)\n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = getData(MOVIELENS_DIR, 'u.data')\n",
    "rating_df_train = getData(MOVIELENS_DIR, 'u1.base')\n",
    "rating_df_test = getData(MOVIELENS_DIR, 'u1.test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossValidation(object):\n",
    "    def __init__(self, metric, data_path=MOVIELENS_DIR):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                metric: string. from['RMSE','P@K','R@K']\n",
    "        \"\"\"\n",
    "        self.folds = self._getData(MOVIELENS_DIR)\n",
    "        self.metric_name = metric\n",
    "        self.metric = self._getMetric(self.metric_name)\n",
    "        \n",
    "    def _getMetric(self, metric_name):\n",
    "        \"\"\"\n",
    "            Don't change this\n",
    "        \"\"\"\n",
    "        switcher = {\n",
    "            'RMSE': self.rmse,\n",
    "            'P@K': self.patk,\n",
    "            'R@K': self.ratk,\n",
    "            'RPrecision': self.rprecision\n",
    "        }\n",
    "        \n",
    "        return switcher[metric_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def rmse(data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        return sqrt(mean_squared_error(data[pred], data[true]))\n",
    "    \n",
    "    # Precision at k\n",
    "    def patk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items retrived\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "    \n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumPrecisions = 0\n",
    "        countPrecisions = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Calculate precision\n",
    "            precision = float(len([item for item in topK if item in userTestVector]))/len(topK)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumPrecisions += precision\n",
    "            countPrecisions += 1\n",
    "\n",
    "        # Return average P@k\n",
    "        return float(sumPrecisions)/countPrecisions\n",
    "    \n",
    "    # Recall at k\n",
    "    def ratk(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame. \n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet =  self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRecalls = 0\n",
    "        countRecalls = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID,:]\n",
    "            topK = nlargest(k, range(len(userVector)), userVector.take)\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID,:]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            # Calculate recall\n",
    "            recall = float(len([item for item in topK if item in userTestVector]))/len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRecalls += recall\n",
    "            countRecalls += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRecalls)/countRecalls\n",
    "\n",
    "    def rprecision(self, data, k, num_users, num_items, pred, true='rating'):\n",
    "        \"\"\"\n",
    "            data: pandas DataFrame.\n",
    "            k: top-k items relevant\n",
    "            pred: string. Column name that corresponding to the prediction\n",
    "            true: string. Column name that corresponding to the true rating\n",
    "        \"\"\"\n",
    "        prediction = self.getMatrix(data, num_users, num_items, pred)\n",
    "        testSet = self.getMatrix(data, num_users, num_items, true)\n",
    "        # Initialize sum and count vars for average calculation\n",
    "        sumRPs = 0\n",
    "        countRPs = 0\n",
    "\n",
    "        # Define function for converting 1-5 rating to 0/1 (like / don't like)\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        for userID in range(num_users):\n",
    "            # Pick top K based on predicted rating\n",
    "            userVector = prediction[userID, :]\n",
    "\n",
    "\n",
    "            # Convert test set ratings to like / don't like\n",
    "            userTestVector = vf(testSet[userID, :]).nonzero()[0]\n",
    "\n",
    "            # Ignore user if has no ratings in the test set\n",
    "            if (len(userTestVector) == 0):\n",
    "                continue\n",
    "\n",
    "            topK = nlargest(len(userTestVector), range(len(userVector)), userVector.take)\n",
    "            # Calculate recall\n",
    "            rp = float(len([item for item in topK if item in userTestVector])) / len(userTestVector)\n",
    "\n",
    "            # Update sum and count\n",
    "            sumRPs += rp\n",
    "            countRPs += 1\n",
    "\n",
    "        # Return average R@k\n",
    "        return float(sumRPs) / countRPs\n",
    "\n",
    "    @staticmethod\n",
    "    def getMatrix(rating_df, num_users, num_items, column_name):\n",
    "        matrix = np.zeros((num_users, num_items))\n",
    "    \n",
    "        for (index, userID, itemID, value) in rating_df[['userID','itemID', column_name]].itertuples():\n",
    "            matrix[userID-1, itemID-1] = value\n",
    "            \n",
    "        return matrix\n",
    "    \n",
    "    @staticmethod\n",
    "    def _getData(data_path):\n",
    "        \"\"\"\n",
    "            Don't change this function\n",
    "        \"\"\"\n",
    "        folds = []\n",
    "        data_types = ['u{0}.base','u{0}.test']\n",
    "        for i in range(1,6):\n",
    "            train_set = getData(data_path, data_types[0].format(i))\n",
    "            test_set = getData(data_path, data_types[1].format(i))\n",
    "            folds.append([train_set, test_set])\n",
    "        return folds\n",
    "    \n",
    "    def run(self, algorithms, num_users, num_items, k=1):\n",
    "        \"\"\"\n",
    "            5-fold cross-validation\n",
    "            algorithms: list. a list of algorithms. \n",
    "                        eg: [user_cosine_recsys, item_euclidean_recsys]\n",
    "        \"\"\"\n",
    "        \n",
    "        scores = {}\n",
    "        for algorithm in algorithms:\n",
    "            print('Processing algorithm {0}'.format(algorithm.getPredColName()))\n",
    "            fold_scores = []\n",
    "            for fold in self.folds:\n",
    "                algorithm.reset()\n",
    "                algorithm.predict_all(fold[0], num_users, num_items)\n",
    "                prediction = algorithm.evaluate_test(fold[1])\n",
    "                pred_col = algorithm.getPredColName()\n",
    "                fold_scores.append(self.metric(prediction, k, num_users, num_items, pred_col))\n",
    "                \n",
    "            mean = np.mean(fold_scores)\n",
    "            ci_low, ci_high = stats.t.interval(0.95, len(fold_scores)-1, loc=mean, scale=stats.sem(fold_scores))\n",
    "            scores[algorithm.getPredColName()] = [fold_scores, mean, ci_low, ci_high]\n",
    "            \n",
    "        results = scores    \n",
    "    \n",
    "        return results\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataPreprocessor(rating_df, num_users, num_items):\n",
    "    \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating' ...]\n",
    "            num_row: int. number of users\n",
    "            num_col: int. number of items\n",
    "            \n",
    "        OUTPUT:\n",
    "            matrix: 2D numpy array. \n",
    "            \n",
    "        NOTE 1: see where something very similar is done in the lab in function 'buildUserItemMatrix'    \n",
    "            \n",
    "        NOTE 2: data can have more columns, but your function should ignore \n",
    "              additional columns.\n",
    "    \"\"\"\n",
    "    ########### your code goes here ###########\n",
    "    matrix = np.zeros((num_users, num_items), dtype=np.int8)\n",
    "    for (index, userID, itemID, rating, timestamp) in rating_df.itertuples():\n",
    "        matrix[userID-1, itemID-1] = rating\n",
    "    ###########         end         ###########\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompetitionRecSys(object):\n",
    "    \"\"\"\n",
    "    You can define new methods if you need. Don't use global variables in the class. \n",
    "    \"\"\"\n",
    "    def __init__(self, ):\n",
    "        \"\"\"\n",
    "        Initialization of the class\n",
    "        1. Make sure to fill out self.pred_column_name, the name you give  to your competition method\n",
    "        \n",
    "        \"\"\"\n",
    "        ########## your code goes here ###########\n",
    "        self.pred_column_name = 'ghrs'\n",
    "        self.num_feat = 10  # Number of latent features,\n",
    "        self.epsilon = 1  # learning rate,\n",
    "        self._lambda = 0.1  # L2 regularization,\n",
    "        self.momentum = 0.8  # momentum of the gradient,\n",
    "        self.maxepoch = 50  # Number of epoch before stop,\n",
    "        self.num_batches = 10  # Number of batches in each epoch (for SGD optimization),\n",
    "        self.batch_size = 1000  # Number of training samples used in each batches (for SGD optimization)\n",
    "        self.test = False\n",
    "        self.w_Item = None  # Item feature vectors\n",
    "        self.w_User = None  # User feature vectors\n",
    "\n",
    "        self.rmse_train = []\n",
    "        self.rmse_test = []\n",
    "        self.pred_column_name='PMF'\n",
    "        ###########         end         ###########\n",
    "\n",
    "    def predict_all(self, train_vec, num_user, num_item):\n",
    "        \"\"\"\n",
    "        INPUT: \n",
    "            data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            num_user: scalar. number of users\n",
    "            num_item: scalar. number of items\n",
    "        OUTPUT:\n",
    "            no return... \n",
    "        \n",
    "        NOTES:\n",
    "            This function is where you train your model\n",
    "        \"\"\"\n",
    "                \n",
    "        ########## your code goes here ###########\n",
    "        #global x\n",
    "        #x = dataPreprocessor(train_vec, num_user, num_item)\n",
    "        train_matrix = dataPreprocessor(train_vec, num_user, num_item)\n",
    "        predictionMatrix1 = np.zeros((num_user, num_item))\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            if rating == 0:\n",
    "                userVector = train_matrix[user, :]\n",
    "                ratedItems = userVector[userVector.nonzero()]\n",
    "                if ratedItems.size == 0:\n",
    "                    itemAvg = 0\n",
    "                else:\n",
    "                    itemAvg = ratedItems.mean()\n",
    "                predictionMatrix1[user, item] = itemAvg\n",
    "                \n",
    "        predictionMatrix2 = np.zeros((num_user, num_item))\n",
    "        vf = np.vectorize(lambda x: 1 if x >= 4 else 0)\n",
    "        itemPopularity = np.zeros((num_item))\n",
    "        for item in range(num_item):\n",
    "            numOfUsersRated = len(train_matrix[:, item].nonzero()[0])\n",
    "            numOfUsersLiked = len(vf(train_matrix[:, item]).nonzero()[0])\n",
    "            if numOfUsersRated == 0:\n",
    "                itemPopularity[item] = 0\n",
    "            else:\n",
    "                itemPopularity[item] = numOfUsersLiked/numOfUsersRated\n",
    "        for (user,item), rating in np.ndenumerate(train_matrix):\n",
    "            if rating == 0:\n",
    "                predictionMatrix2[user, item] = itemPopularity[item]\n",
    "                \n",
    "        temp_matrix = np.zeros(train_matrix.shape)\n",
    "        temp_matrix[train_matrix.nonzero()] = 1\n",
    "        uu_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
    "        normalizer = np.matmul(uu_similarity, temp_matrix)\n",
    "        normalizer[normalizer == 0] = 1e-5\n",
    "        model1 = np.matmul(uu_similarity, train_matrix)/normalizer\n",
    "        useraverage = np.sum(train_matrix, axis=1)/np.sum(temp_matrix, axis=1)\n",
    "        columns = np.sum(model1, axis=0)\n",
    "        model1[:, columns==0] = model1[:, columns==0] + np.expand_dims(useraverage, axis=1)\n",
    "        train_matrix = train_matrix.T\n",
    "        temp_matrix = np.zeros(train_matrix.shape)\n",
    "        temp_matrix[train_matrix.nonzero()] = 1\n",
    "        ii_similarity = 1 - pairwise_distances(train_matrix, metric='cosine')\n",
    "        normalizer = np.matmul(ii_similarity, temp_matrix)\n",
    "        normalizer[normalizer == 0] = 1e-5\n",
    "        model2 = np.transpose(np.matmul(ii_similarity, train_matrix)/normalizer)\n",
    "        \n",
    "        '''# select 'userID', 'itemID', 'rating only\n",
    "        train_vec = train_vec.iloc[:, :3].values\n",
    "        if self.test:\n",
    "          train_vec, val_vec = train_test_split(train_vec)\n",
    "          pairs_val = val_vec.shape[0]\n",
    "          self.mean_rating_test = np.mean(val_vec[:, 2])\n",
    "        self.mean_rating_train = np.mean(train_vec[:, 2])  # avg rating\n",
    "        pairs_train = train_vec.shape[0]  # num of rating\n",
    "\n",
    "\n",
    "        # to avoid out of bound\n",
    "        num_user += 1\n",
    "        num_item += 1\n",
    "        # initialize\n",
    "        self.epoch = 0\n",
    "        ########### your code goes here ###########\n",
    "        self.w_Item = np.random.randn(num_item, self.num_feat)\n",
    "        self.w_User = np.random.randn(num_user, self.num_feat)\n",
    "        ###########         end         ###########\n",
    "\n",
    "        self.w_Item_inc = np.zeros((num_item, self.num_feat))  # accumulate the gradient\n",
    "        self.w_User_inc = np.zeros((num_user, self.num_feat))  # accumulate the gradient\n",
    "        while self.epoch < self.maxepoch:\n",
    "            self.epoch += 1\n",
    "\n",
    "            # Shuffle training truples\n",
    "            shuffled_order = np.arange(train_vec.shape[0])\n",
    "            np.random.shuffle(shuffled_order)  #shuffled\n",
    "\n",
    "            # Batch update\n",
    "            for batch in range(self.num_batches):\n",
    "                # print \"epoch %d batch %d\" % (self.epoch, batch+1)\n",
    "\n",
    "                test = np.arange(self.batch_size * batch, self.batch_size * (batch + 1))\n",
    "                batch_idx = np.mod(test, shuffled_order.shape[0])  # get the real data index\n",
    "\n",
    "\n",
    "                batch_UserID = np.array(train_vec[shuffled_order[batch_idx], 0], dtype='int32')\n",
    "                batch_ItemID = np.array(train_vec[shuffled_order[batch_idx], 1], dtype='int32')\n",
    "\n",
    "\n",
    "                # Compute mean rating subtracted rating\n",
    "                ########### your code goes here ###########\n",
    "                pred_out = np.sum(self.w_User[batch_UserID,:]*self.w_Item[batch_ItemID,:], axis=1) #size (batch_size, )\n",
    "                ###########         end         ###########\n",
    "\n",
    "                rawErr = pred_out + self.mean_rating_train - train_vec[shuffled_order[batch_idx], 2]\n",
    "\n",
    "                # Compute gradients\n",
    "                Ix_User = 2 * np.multiply(rawErr[:, np.newaxis], self.w_Item[batch_ItemID, :]) \\\n",
    "                       + self._lambda * self.w_User[batch_UserID, :]\n",
    "                Ix_Item = 2 * np.multiply(rawErr[:, np.newaxis], self.w_User[batch_UserID, :]) \\\n",
    "                       + self._lambda * (self.w_Item[batch_ItemID, :])  # np.newaxis :increase the dimension\n",
    "\n",
    "                dw_Item = np.zeros((num_item, self.num_feat))\n",
    "                dw_User = np.zeros((num_user, self.num_feat))\n",
    "\n",
    "                # loop to aggreate the gradients of the same element\n",
    "                for i in range(self.batch_size):\n",
    "                    dw_Item[batch_ItemID[i], :] += Ix_Item[i, :]\n",
    "                    dw_User[batch_UserID[i], :] += Ix_User[i, :]\n",
    "\n",
    "                # Update with momentum\n",
    "                self.w_Item_inc = self.momentum * self.w_Item_inc + self.epsilon * dw_Item / self.batch_size\n",
    "                self.w_User_inc = self.momentum * self.w_User_inc + self.epsilon * dw_User / self.batch_size\n",
    "\n",
    "                self.w_Item = self.w_Item - self.w_Item_inc\n",
    "                self.w_User = self.w_User - self.w_User_inc\n",
    "\n",
    "                # Compute Compute mean rating subtracted rating\n",
    "                if batch == self.num_batches - 1:\n",
    "                    train_user_idx = np.array(train_vec[:, 0], dtype='int32')\n",
    "                    train_item_idx = np.array(train_vec[:, 1], dtype='int32')\n",
    "\n",
    "                    # Compute Compute mean rating subtracted rating\n",
    "                    ########### your code goes here ###########\n",
    "                    pred_out = np.sum(self.w_User[train_user_idx,:]*self.w_Item[train_item_idx,:], axis=1)\n",
    "                    ###########         end         ###########\n",
    "                    rawErr = pred_out + self.mean_rating_train - train_vec[:, 2]\n",
    "                    obj = np.linalg.norm(rawErr) ** 2 \\\n",
    "                          + 0.5 * self._lambda * (np.linalg.norm(self.w_User) ** 2 + np.linalg.norm(self.w_Item) ** 2)\n",
    "\n",
    "                    self.rmse_train.append(np.sqrt(obj / pairs_train))\n",
    "\n",
    "                # Compute validation error\n",
    "                if batch == self.num_batches - 1 and self.test:\n",
    "                    val_user_idx = np.array(val_vec[:, 0], dtype='int32')\n",
    "                    val_item_idx = np.array(val_vec[:, 1], dtype='int32')\n",
    "\n",
    "                    # Compute Compute mean rating subtracted rating\n",
    "                    ########### your code goes here ###########\n",
    "                    pred_out = np.sum(self.w_User[val_user_idx,:]*self.w_Item[val_item_idx,:], axis=1)\n",
    "                    ###########         end         ###########\n",
    "\n",
    "                    rawErr = pred_out + self.mean_rating_test - val_vec[:, 2]\n",
    "                    self.rmse_test.append(np.linalg.norm(rawErr) / np.sqrt(pairs_val))\n",
    "        \n",
    "        model3 = np.einsum('ik,jk->ji',self.w_Item, self.w_User) + self.mean_rating_train\n",
    "        w = torch.normal(0,1,size=(5,),requires_grad=True)\n",
    "        b = torch.zeros(1,requires_grad=True)\n",
    "        y = torch.tensor(train_vec[:, 2], dtype=w.dtype)'''\n",
    "        x = torch.stack((torch.tensor(predictionMatrix1), torch.tensor(predictionMatrix2), torch.tensor(model1), torch.tensor(model2)))\n",
    "        x = x.to(torch.float32)\n",
    "        #criterion = torch.nn.MSELoss()\n",
    "        pred = 1/4*x[0]+1*x[1]+1/4*x[2]+1/4*x[3]#+x[4]/3\n",
    "        #for i in range(20):\n",
    "        #    pred = sum([w[i]*x[i] for i in range(5)])+b\n",
    "        #    loss = torch.sqrt(criterion(pred[np.array(train_vec[:, 0], dtype='int32')-1, np.array(train_vec[:, 1], dtype='int32')-1], y))\n",
    "        #    loss.backward()\n",
    "        #    w.data = w.data - 0.01 * w.grad.data\n",
    "        #    b.data = b.data - 0.01 * b.grad.data\n",
    "        #    w.grad.data.zero_()\n",
    "        #    b.grad.data.zero_()\n",
    "        self.__model = pred\n",
    "        ###########         end         ###########\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def evaluate_test(self, test_df, copy=False):\n",
    "        \"\"\"\n",
    "            INPUT:\n",
    "                data: pandas DataFrame. columns=['userID', 'itemID', 'rating'...]\n",
    "            OUTPUT:\n",
    "                predictions:  pandas DataFrame. \n",
    "                              columns=['userID', 'itemID', 'rating', 'base-method'...]\n",
    "\n",
    "            NOTES:\n",
    "            This function is where your model makes prediction \n",
    "            Please fill out: prediction.loc[index, self.pred_column_name] = None                            \n",
    "                              \n",
    "        \"\"\"\n",
    "        if copy:\n",
    "            prediction = pd.DataFrame(test_df.copy(), columns=['userID', 'itemID', 'rating'])\n",
    "        else:\n",
    "            prediction = pd.DataFrame(test_df, columns=['userID', 'itemID', 'rating'])\n",
    "        prediction[self.pred_column_name] = np.nan\n",
    "        \n",
    "        for (index, \n",
    "             userID, \n",
    "             itemID) in tqdm(prediction[['userID','itemID']].itertuples()):\n",
    "            ########### your code goes here ###########\n",
    "            prediction.loc[index, self.pred_column_name] = self.__model[userID-1, itemID-1].item()\n",
    "            ###########         end         ###########\n",
    "\n",
    "        return prediction\n",
    "          \n",
    "    def getPredColName(self):\n",
    "        \"\"\"\n",
    "            return prediction column name\n",
    "        \"\"\"\n",
    "        return self.pred_column_name\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            reuse the instance of the class by removing model\n",
    "        \"\"\"\n",
    "        ########### your code goes here ###########\n",
    "        pass\n",
    "        ##########         end         ###########\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing algorithm PMF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20000it [00:01, 18192.05it/s]\n",
      "20000it [00:01, 18231.57it/s]\n",
      "20000it [00:01, 17996.72it/s]\n",
      "20000it [00:01, 18152.06it/s]\n",
      "20000it [00:01, 17889.70it/s]\n"
     ]
    }
   ],
   "source": [
    "competition = CompetitionRecSys()\n",
    "algorithm_instances = [competition]\n",
    "cv_rp = CrossValidation('RPrecision')\n",
    "rp = cv_rp.run(algorithm_instances,  len(rating_df.userID.unique()), len(rating_df.itemID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PMF': [[0.7195169794846775, 0.7142932499224122, 0.7206675396663675, 0.7219255845275684, 0.7363732038347363], 0.7225553114871524, 0.7123089968389731, 0.7328016261353316]}\n"
     ]
    }
   ],
   "source": [
    "print(rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for validation only\n",
    "ROW_NUM = 943\n",
    "COL_NUM = 1682\n",
    "RATING_COL = 'rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateDataPreprocessor(path=MOVIELENS_DIR, getData=getData, getMatrix=CrossValidation.getMatrix):\n",
    "    validation_df = getData(MOVIELENS_DIR, 'u1.test')\n",
    "    try:\n",
    "        matrix = getMatrix(validation_df, ROW_NUM, COL_NUM, RATING_COL)\n",
    "    except:\n",
    "        print('dataPreprocessor function has error')\n",
    "        return\n",
    "    try:\n",
    "        assert(matrix.shape == (ROW_NUM,COL_NUM)),\\\n",
    "        \"Shape of matrix{0} doesn't match predefined shape (943,1682)\".format(matrix.shape)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = validateDataPreprocessor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
